{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d0030e",
   "metadata": {},
   "source": [
    "# Presentation Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfa082",
   "metadata": {},
   "source": [
    "Use LLMs to produce presentation decks is a great time saving exercise. I have been playing with tools like [tome](https://tome.app/) and [gamma](https://gamma.app/) and was well impressed by it. So I thought why don't I build my own.\n",
    "\n",
    "Instead of asking LLMs to do everything from ideation to generating content, I take the approach of extracting content-rich text from a YouTube video, then feeding the text to LLM as context in order to generate presentation slides.\n",
    "\n",
    "![presentation_gen_flow](presentation_gen_flow.png)\n",
    "\n",
    "The example chosen is a Google Cloud training video that summarises key modules covered throughout the [Google Cloud Core Infrastructure](https://www.youtube.com/watch?v=dAsKylaxuSo) course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96a083",
   "metadata": {},
   "source": [
    "## Donwload Audio File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a6311",
   "metadata": {},
   "source": [
    "First we need to extract the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d426ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/meng.lin/workspace/GenAI/Playground/326697.mp4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytube\n",
    "\n",
    "video = \"https://www.youtube.com/watch?v=dAsKylaxuSo\"\n",
    "data = pytube.YouTube(video)\n",
    "audio = data.streams.get_audio_only()\n",
    "audio.download(filename = \"326697.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9ea8f",
   "metadata": {},
   "source": [
    "> NOTE: You may come across a known issue with `pytube`, `pytube.exceptions.RegexMatchError`. You can refer to this [solution](https://github.com/pytube/pytube/issues/1678#issuecomment-1603948730) to patch `pytube` before the issue is properly fixed and merged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e4dbc",
   "metadata": {},
   "source": [
    "## Transcribe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd207a4",
   "metadata": {},
   "source": [
    "Then use an OpenAI model called [Whisper](https://openai.com/research/whisper) to transform speech to text. For more detailed walk through of Whisper, refer to this [tutorial](../OpenAI/102_audio.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80bd0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"tiny\")\n",
    "transcribe = model.transcribe(\"326697.mp4\", fp16 = False)\n",
    "with open('326697.txt', 'w') as f:\n",
    "    f.write(transcribe['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501970c",
   "metadata": {},
   "source": [
    "## Generate Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc6734",
   "metadata": {},
   "source": [
    "Now we load up the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a173f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab54417",
   "metadata": {},
   "source": [
    "Since the content is likely to be larger than the current 4K context window with `gpt-3.5-turbo`. I am listing all available models, and see if the newly announced [16K context window model](https://openai.com/blog/function-calling-and-other-api-updates) is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa423d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whisper-1\n",
      "babbage\n",
      "davinci\n",
      "text-davinci-edit-001\n",
      "babbage-code-search-code\n",
      "text-similarity-babbage-001\n",
      "code-davinci-edit-001\n",
      "text-davinci-001\n",
      "ada\n",
      "babbage-code-search-text\n",
      "babbage-similarity\n",
      "code-search-babbage-text-001\n",
      "text-curie-001\n",
      "code-search-babbage-code-001\n",
      "gpt-3.5-turbo-0613\n",
      "text-ada-001\n",
      "text-similarity-ada-001\n",
      "curie-instruct-beta\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo\n",
      "ada-code-search-code\n",
      "ada-similarity\n",
      "code-search-ada-text-001\n",
      "text-search-ada-query-001\n",
      "davinci-search-document\n",
      "ada-code-search-text\n",
      "text-search-ada-doc-001\n",
      "davinci-instruct-beta\n",
      "text-similarity-curie-001\n",
      "code-search-ada-code-001\n",
      "ada-search-query\n",
      "text-search-davinci-query-001\n",
      "curie-search-query\n",
      "davinci-search-query\n",
      "babbage-search-document\n",
      "ada-search-document\n",
      "text-search-curie-query-001\n",
      "text-search-babbage-doc-001\n",
      "curie-search-document\n",
      "text-search-curie-doc-001\n",
      "babbage-search-query\n",
      "text-babbage-001\n",
      "text-search-davinci-doc-001\n",
      "text-search-babbage-query-001\n",
      "curie-similarity\n",
      "gpt-3.5-turbo-16k-0613\n",
      "curie\n",
      "text-embedding-ada-002\n",
      "gpt-3.5-turbo-16k\n",
      "text-similarity-davinci-001\n",
      "text-davinci-002\n",
      "text-davinci-003\n",
      "davinci-similarity\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = openai_api_key\n",
    "models = openai.Model.list()\n",
    "\n",
    "for model in models[\"data\"]:\n",
    "    print(model[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70736dd",
   "metadata": {},
   "source": [
    "The answer is yes, the name of the model is `gpt-3.5-turbo-16k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "676bad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\", \n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
    ")\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91674453",
   "metadata": {},
   "source": [
    "Here is the prompt used to carry out the task. The prompt contains the following instructions:\n",
    "- The task\n",
    "- The format requirements\n",
    "- The context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f6396cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"326697.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Break down the context module by module. List the keynotes of each module using bullet points. \n",
    "Output the result in MARKDOWN format.\n",
    "\n",
    "% FORMAT %\n",
    "\n",
    "# Title\n",
    "- bullet 1\n",
    "    - sub-bullet 1\n",
    "    - sub-bullet 2\n",
    "    - sub-bullet 3\n",
    "- bullet 2\n",
    "- bullet 3\n",
    "\n",
    "# Title\n",
    "- bullet 1\n",
    "    - sub-bullet 1\n",
    "    - sub-bullet 2\n",
    "    - ...\n",
    "- bullet 2\n",
    "- ...\n",
    "\n",
    "% CONTEXT %\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5d8b8",
   "metadata": {},
   "source": [
    "Invoke OpenAI model to generate the presentation in `Markdown` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f167752a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Module 1\\n- Introduction to Google Cloud and Cloud Computing\\n- Managed infrastructure and managed services \\n    - Infrastructure as a Service (IaaS)\\n    - Platform as a Service (PaaS)\\n- Google Cloud Network\\n- Google Cloud's focus on security \\n- Google publishes key elements of technology using open source licenses\\n- Google Cloud's pricing structure and billing tools\\n\\n# Module 2\\n- Google Cloud Resource Hierarchy \\n    - Resources\\n    - Projects\\n    - Folders\\n    - Organization Load\\n- Defining policies and downward inheritance\\n- Cloud Identity and Access Management (Cloud IAM)\\n- Ways to access and interact with Google Cloud\\n    - Cloud Console\\n    - Cloud SDK and Cloud Shell\\n    - APIs\\n    - Cloud Console mobile app\\n\\n# Module 3\\n- How Compute Engine works\\n- Virtual machines and virtual networking\\n- Virtual Private Cloud (VPC)\\n- Compute Engine's auto-scaling feature\\n- Google Virtual Private Cloud compatibility features\\n    - Routing tables\\n    - Firewalls\\n    - VPC peering\\n    - Shared VPC\\n- Cloud Load Balancing\\n- Interconnecting other networks with Google VPC\\n\\n# Module 4\\n- Google Cloud's core storage options\\n    - Cloud Storage\\n    - Cloud Bigtable\\n    - Cloud SQL\\n    - Cloud Spanner\\n    - Firestore\\n- Storage classes in Cloud Storage\\n    - Standard storage\\n    - Nearline storage\\n    - Coldline storage\\n    - Archive storage\\n\\n# Module 5\\n- Introduction to containers\\n- Kubernetes\\n- Google Kubernetes Engine (GKE)\\n- Anthos\\n\\n# Module 6\\n- Developing applications in the cloud\\n- App Engine\\n    - Standard environment\\n    - Flexible environment\\n- API management tools\\n    - Cloud Endpoints\\n    - Apigee\\n- Cloud Run\\n\\n# Module 7\\n- Developing and deploying in the cloud\\n- Cloud Source Repositories\\n- Cloud Functions\\n- Terraform\\n\\n# Module 8\\n- Logging and monitoring on Google Cloud\\n- Four golden signals\\n    - Latency\\n    - Traffic\\n    - Saturation\\n    - Errors\\n- Service-level indicators (SLIs)\\n- Service-level objectives (SLOs)\\n- Service-level agreements (SLAs)\\n- Google's integrated observability tools\\n    - Cloud Monitoring\\n    - Cloud Logging\\n    - Error Reporting\\n    - Debugger\\n    - Cloud Trace\\n    - Cloud Profile\\n\\n# Conclusion\\n- Further training and learning paths available at cloud.google.com/training\\n- Google Cloud certification offerings at cloud.google.com/certifications\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\", \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4ebb4",
   "metadata": {},
   "source": [
    "The result looks pretty decent, however, there's no better way to test the result, apart from putting it to work. In order to do that, we need to transform the markdown into presentation using a library `python-pptx`. You need to `pip install` if you don't have it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c877f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pptx import Presentation\n",
    "\n",
    "presentation = Presentation()\n",
    "\n",
    "title_slide_layout = presentation.slide_layouts[0]\n",
    "slide = presentation.slides.add_slide(title_slide_layout)\n",
    "slide.shapes.title.text = \"Course Summary\"\n",
    "slide.placeholders[1].text = \"Generated from YouTube video\"\n",
    "\n",
    "pages = completion.choices[0].message.content.split(\"\\n\\n\")\n",
    "\n",
    "for i, page in enumerate(pages):\n",
    "    lines = page.split(\"\\n\")\n",
    "    bullet_slide_layout = presentation.slide_layouts[1]\n",
    "    slide = presentation.slides.add_slide(bullet_slide_layout)\n",
    "    shapes = slide.shapes\n",
    "    \n",
    "    title_shape = shapes.title\n",
    "    body_shape = shapes.placeholders[1]\n",
    "    tf = body_shape.text_frame\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith(\"#\"):\n",
    "            title_shape.text = line[1:].strip()\n",
    "        if line.startswith(\"-\"):\n",
    "            p = tf.add_paragraph()\n",
    "            p.text = line[1:].strip()\n",
    "            p.level = 1\n",
    "\n",
    "output_filename = \"326697.pptx\"\n",
    "presentation.save(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b0d37",
   "metadata": {},
   "source": [
    "Now the result is here. In comparison, it's actually good. \n",
    "\n",
    "It's worth pointing out:\n",
    "- The presentation has a minimalist design, which is due to the template used is pretty blunt.\n",
    "- The content provided to LLMs still dictates the quality of presentation, not the other way round!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf98326",
   "metadata": {},
   "source": [
    "## Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635fdb8",
   "metadata": {},
   "source": [
    "- The output format can also be in `JSON`. By using JSON format, it can actually help reduce the amount of manual data manipulation, which really defeats the point of using markdown. And the whole post-processing can be a lot easier and less fiddly.\n",
    "- I used `python-pptx` to create presentation, is this the best option out there? And what would be the best template to use? Can the library handle more sophisticated design layout?\n",
    "- The biggest question is and still is: what does a good engaging presentation look like? I think having good templates and design would be a good start, however, the content and a personal style are still the key."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
