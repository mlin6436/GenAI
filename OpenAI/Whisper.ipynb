{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da491ba",
   "metadata": {},
   "source": [
    "# Whisper\n",
    "\n",
    "This is a quick experiment to play with OpenAI's multimodal capability, specifically speech to text transformation. The speech recognition model used is called [Whisper](https://openai.com/research/whisper), and it's completely free and open-source.\n",
    "\n",
    "Whisper is trained on 680,000 hours of multilingual data and is capable of dealing with complex inputs such as accents, background noise etc. You can take a look into the [technical details](https://github.com/openai/whisper).\n",
    "\n",
    "There are a number of available models, and this is useful to know as it will be configured in the code.\n",
    "\n",
    "|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
    "|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
    "|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
    "|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
    "| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
    "| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
    "| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c620ddf",
   "metadata": {},
   "source": [
    "For the purpose of this experiment, I will first download the famous `I have a particular set of skills` speech from `Liam Neeson`, I strongly encourage you to checkout the original film [Taken](https://en.wikipedia.org/wiki/Taken_(film)) if you haven't heard of it before. Then I will only extract audio from the clip, before transcribing the audio into text using Whisper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -— upgrade pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ef1800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/meng.lin/workspace/GenAI/OpenAI/sample.mp4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytube\n",
    "\n",
    "video = \"https://www.youtube.com/watch?v=-LIIf7E-qFI\" # I have a particular set of skills - Liam Neeson\n",
    "data = pytube.YouTube(video)\n",
    "audio = data.streams.get_audio_only()\n",
    "audio.download(filename=\"sample.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c4f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee8bd56",
   "metadata": {},
   "source": [
    "You may receive a warning `UserWarning: FP16 is not supported on CPU; using FP32 instead warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")` during the transcribe, it's a nuance that should have been sorted out. You can dig deeper into this topic [here](https://www.quora.com/What-is-the-difference-between-FP16-and-FP32-when-doing-deep-learning) if this is the kind of topic that interests you. Otherwise, you can add `fp16=False` in code or `--fp16 False` in command line to get around this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d07bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.87G/2.87G [07:27<00:00, 6.90MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I don't know who you are. I don't know what you want. If you are looking for a ransom, I can tell you I don't have money. But what I do have are a very particular set of skills. Skills I have acquired over a very long career. Skills that make me a nightmare for people like you. If you let my daughter go now, that will be the end of it. I will not look for you. I will not pursue you. But if you don't, I will look for you. I will find you. And I will kill you. Good luck.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"large\")\n",
    "transcribe = model.transcribe(\"sample.mp4\", fp16=False)\n",
    "transcribe['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fca30f",
   "metadata": {},
   "source": [
    "As you can see the result is actually good. \n",
    "\n",
    "However, there are a couple of things I'd like to point out:\n",
    "- The result looks pretty decent is because the `large` model was used in this case. Otherwise, you would have seen result that says something like this `Skills I have acquired are for a very long career`, which is supposed to be `Skills I have acquired over a very long career`.\n",
    "- Also note that larger the model is used, longer it would take to produce the result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
