{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38694d91",
   "metadata": {},
   "source": [
    "# Whisper\n",
    "\n",
    "This is a quick experiment to play with OpenAI's multimodal capability, specifically speech to text transformation. The speech recognition model used is called [Whisper](https://openai.com/research/whisper), and it's completely free and open-source.\n",
    "\n",
    "Whisper is trained on 680,000 hours of multilingual data and is capable of dealing with complex inputs such as accents, background noise etc. You can take a look into the [technical details](https://github.com/openai/whisper).\n",
    "\n",
    "There are a number of available models, and this is useful to know as it will be configured in the code.\n",
    "\n",
    "Size\tParameters\tEnglish-only model\tMultilingual model\tRequired VRAM\tRelative speed\n",
    "tiny\t39 M\ttiny.en\ttiny\t~1 GB\t~32x\n",
    "base\t74 M\tbase.en\tbase\t~1 GB\t~16x\n",
    "small\t244 M\tsmall.en\tsmall\t~2 GB\t~6x\n",
    "medium\t769 M\tmedium.en\tmedium\t~5 GB\t~2x\n",
    "large\t1550 M\tN/A\tlarge\t~10 GB\t1x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafec324",
   "metadata": {},
   "source": [
    "For the purpose of this experiment, I will first download the famous `I have a particular set of skills` speech from `Liam Neeson`, I strongly encourage you to checkout the original film [Taken](https://en.wikipedia.org/wiki/Taken_(film)) if you haven't heard of it before. Then I will only extract audio from the clip, before transcribing the audio into text using Whisper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -â€” upgrade pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ef1800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/meng.lin/workspace/GenAI/OpenAI/sample.mp4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytube\n",
    "\n",
    "video = \"https://www.youtube.com/watch?v=-LIIf7E-qFI\" # I have a particular set of skills - Liam Neeson\n",
    "data = pytube.YouTube(video)\n",
    "audio = data.streams.get_audio_only()\n",
    "audio.download(filename=\"sample.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf40d519",
   "metadata": {},
   "source": [
    "You may receive a warning `UserWarning: FP16 is not supported on CPU; using FP32 instead warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")` during the transcribe, it's a nuance that should have been sorted out. You can dig deeper into this topic [here](https://www.quora.com/What-is-the-difference-between-FP16-and-FP32-when-doing-deep-learning) if this is the kind of topic that interests you. Otherwise, you can add `fp16=False` in code or `--fp16 False` in command line to get around this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d07bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I don't know who you are. I don't know what you want. If you're looking for ransom, I can tell you I don't have money, but what I do have. I'm a very particular set of skills. Skills I have acquired are for a very long career. The skills that make me and I matter people like you. If you let my daughter go now, that'll be the end of it. I will not look for you. I will not pursue you. But if you don't, I will look for you. I will find you. And I will kill you. Good luck.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"tiny\")\n",
    "transcribe = model.transcribe(\"sample.mp4\", fp16=False)\n",
    "transcribe['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
